import streamlit as st
from google import genai
from google.genai import types

st.header("ğŸ’¬ Gemini ì±—ë´‡")

# API í‚¤ í™•ì¸
try:
    api_key = st.secrets["gemini"]["GEMINI_API_KEY"]
    if api_key == "your-api-key-here":
        st.warning("âš ï¸ .streamlit/secrets.tomlì—ì„œ GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”!")
        st.stop()
except Exception:
    st.error("API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ì„¤ì • ë¡œë“œ (secrets.tomlì—ì„œ)
gemini_model = st.secrets["gemini"]["model"]
temperature = st.secrets["gemini"]["temperature"]

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ìºì‹±í•˜ì—¬ ì¬ì‚¬ìš©)
@st.cache_resource
def get_client(_api_key):
    return genai.Client(api_key=_api_key)

client = get_client(api_key)

# ìƒì„± ì„¤ì •
generation_config = types.GenerateContentConfig(
    temperature=temperature,
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì‚¬ìš©ìë³„ ì±„íŒ… ì„¸ì…˜)
if "chat" not in st.session_state:
    st.session_state.chat = client.chats.create(model=gemini_model, config=generation_config)
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
    st.session_state.chat = client.chats.create(model=gemini_model, config=generation_config)
    st.session_state.messages = []
    st.rerun()

# ì±„íŒ… UI
# ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ (ê³ ì • ë†’ì´, ìŠ¤í¬ë¡¤ ê°€ëŠ¥)
chat_container = st.container(height=800)

# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
with chat_container:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥ (ì»¨í…Œì´ë„ˆ ë°– = í•­ìƒ ì•„ë˜ì— ê³ ì •)
prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
if prompt:
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with chat_container:
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            full_response = ""

            for chunk in st.session_state.chat.send_message_stream(prompt):
                if chunk.text:
                    full_response += chunk.text
                    response_placeholder.markdown(full_response)

            response_placeholder.markdown(full_response)

    st.session_state.messages.append({"role": "assistant", "content": full_response})
